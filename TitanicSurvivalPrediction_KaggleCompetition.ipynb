{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4974dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "# Function to download and load the Titanic dataset\n",
    "def load_titanic_data():\n",
    "    tarball_path = Path(\"datasets/titanic.tgz\")\n",
    "\n",
    "    # Check if the dataset archive exists locally, if not, download and extract it\n",
    "    if not tarball_path.is_file():\n",
    "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
    "        url = \"https://github.com/ageron/data/raw/main/titanic.tgz\"\n",
    "        urllib.request.urlretrieve(url, tarball_path)\n",
    "        with tarfile.open(tarball_path) as titanic_tarball:\n",
    "            titanic_tarball.extractall(path=\"datasets\")\n",
    "\n",
    "    # Load and return the train and test data as pandas DataFrames\n",
    "    return [pd.read_csv(Path(\"datasets/titanic\") / filename)\n",
    "            for filename in (\"train.csv\", \"test.csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e03f2ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_data, test_data = load_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "844d6e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first few rows of the training data (for initial inspection)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9303ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'PassengerId' as the index for easier tracking and referencing\n",
    "train_data = train_data.set_index(\"PassengerId\")\n",
    "test_data = test_data.set_index(\"PassengerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "188c2585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    object \n",
      " 4   Age       714 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Ticket    891 non-null    object \n",
      " 8   Fare      891 non-null    float64\n",
      " 9   Cabin     204 non-null    object \n",
      " 10  Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display structure and missing values in training data\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4727ecb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the median age of female passengers (may help in imputation strategy)\n",
    "train_data[train_data[\"Sex\"]==\"female\"][\"Age\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0742c500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699113</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526507</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699113    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526507    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.416700    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate descriptive statistics of numerical features\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b8a3452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many passengers survived (target variable distribution)\n",
    "train_data[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46b192e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    491\n",
       "1    216\n",
       "2    184\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore passenger class distribution\n",
    "train_data[\"Pclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbd61075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore gender distribution\n",
    "train_data[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39180f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many people boarded from each port\n",
    "train_data[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90982c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline for numerical features\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Numerical pipeline: impute missing values with median, then scale the features\n",
    "num_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61cbedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline for categorical features\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "522aaa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical pipeline: encode ordinal features, impute with most frequent, then one-hot encode\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"ordinal_encoder\", OrdinalEncoder()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"cat_encoder\", OneHotEncoder(sparse=False)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a93f0193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine numerical and categorical pipelines\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Specify which columns are numerical and which are categorical\n",
    "num_attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "\n",
    "# Combine both pipelines using ColumnTransformer\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", cat_pipeline, cat_attribs),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f13571a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.56573582,  0.43279337, -0.47367361, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.6638609 ,  0.43279337, -0.47367361, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.25833664, -0.4745452 , -0.47367361, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.10463705,  0.43279337,  2.00893337, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.25833664, -0.4745452 , -0.47367361, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.20276213, -0.4745452 , -0.47367361, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the data for training\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "# Apply preprocessing to training data\n",
    "X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65b86b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract target variable\n",
    "y_train = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2af621be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and train the classifier\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "forest_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd477c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data and make predictions\n",
    "# Apply the same preprocessing to the test data (important: use transform, not fit_transform)\n",
    "X_test = preprocess_pipeline.transform(test_data)\n",
    "\n",
    "# Predict survival on the test set\n",
    "y_pred = forest_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00a2c1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8137578027465668"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model using cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Evaluate model accuracy with 10-fold cross-validation\n",
    "forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)\n",
    "\n",
    "# Print the average accuracy\n",
    "forest_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a166fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with PassengerId and corresponding predictions\n",
    "submission_df = pd.DataFrame({\n",
    "    \"PassengerId\": test_data.index,  # Use index since we set it earlier\n",
    "    \"Survived\": y_pred               # Predictions from your model\n",
    "})\n",
    "\n",
    "# Save to a CSV file (don't include the index column in the CSV)\n",
    "submission_df.to_csv(\"titanic_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14a78318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve the above random forest model with feature engineering\n",
    "# Feature: Age bucket (e.g. 0, 15, 30...)\n",
    "train_data[\"AgeBucket\"] = train_data[\"Age\"] // 15 * 15\n",
    "test_data[\"AgeBucket\"] = test_data[\"Age\"] // 15 * 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15dd5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature: Relatives Onboard\n",
    "train_data[\"RelativesOnboard\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\n",
    "test_data[\"RelativesOnboard\"] = test_data[\"SibSp\"] + test_data[\"Parch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "488a4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for the pipeline\n",
    "num_attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"RelativesOnboard\"]\n",
    "cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\", \"AgeBucket\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f04c2b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipelines\n",
    "# Pipeline for numerical features\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04817fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for categorical features\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8099941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine numerical and categorical transformers\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63746430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "y_train = train_data[\"Survived\"]\n",
    "X_test = preprocess_pipeline.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dbee658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Random Forest model\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "forest_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecda31af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation accuracy: 0.8047565543071162\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using 10-fold cross-validation\n",
    "scores = cross_val_score(forest_clf, X_train, y_train, cv=10)\n",
    "print(\"Average cross-validation accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "436d0c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = forest_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e61a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV for Kaggle submission\n",
    "output = pd.DataFrame({\n",
    "    \"PassengerId\": test_data.index,\n",
    "    \"Survived\": y_pred\n",
    "})\n",
    "output.to_csv(\"titanic_submission02.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "530402f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve the Random Forest model with grid search\n",
    "# Grid Search for Best Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4088dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid to search\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [5, 10, None],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9aa7e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base model\n",
    "base_model = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddf59a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=base_model,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1,\n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b100874f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [5, 10, None],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 2],\n",
       "                         'min_samples_split': [2, 5],\n",
       "                         'n_estimators': [100, 200]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train grid search\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e634131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Cross-Validation Score: 0.8294143493817085\n"
     ]
    }
   ],
   "source": [
    "# Output best params and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d71d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using best model and export CSV\n",
    "# Get best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77d5ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_data.index,\n",
    "    \"Survived\": y_pred\n",
    "})\n",
    "\n",
    "# Export to CSV for Kaggle submission\n",
    "submission.to_csv(\"titanic_gridsearch_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "79c3b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model\n",
    "# Feature Engineering\n",
    "# Create new features from existing ones to boost predictive power\n",
    "train_data[\"RelativesOnboard\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\n",
    "train_data[\"IsAlone\"] = (train_data[\"RelativesOnboard\"] == 0).astype(int)\n",
    "train_data[\"Title\"] = train_data[\"Name\"].str.extract(r',\\s*([^\\.]+)\\.')\n",
    "train_data[\"AgeBucket\"] = train_data[\"Age\"] // 15 * 15\n",
    "train_data[\"Deck\"] = train_data[\"Cabin\"].str[0].fillna(\"U\")\n",
    "\n",
    "test_data[\"RelativesOnboard\"] = test_data[\"SibSp\"] + test_data[\"Parch\"]\n",
    "test_data[\"IsAlone\"] = (test_data[\"RelativesOnboard\"] == 0).astype(int)\n",
    "test_data[\"Title\"] = test_data[\"Name\"].str.extract(r',\\s*([^\\.]+)\\.')\n",
    "test_data[\"AgeBucket\"] = test_data[\"Age\"] // 15 * 15\n",
    "test_data[\"Deck\"] = test_data[\"Cabin\"].str[0].fillna(\"U\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1942601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and categorical attributes for processing\n",
    "num_attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"RelativesOnboard\"]\n",
    "cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\", \"Title\", \"Deck\", \"IsAlone\"]\n",
    "\n",
    "# Pipeline for numerical attributes\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for categorical attributes\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Combine both pipelines into a single preprocessing step\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7da0bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for training\n",
    "X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "y_train = train_data[\"Survived\"]\n",
    "X_test = preprocess_pipeline.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c7ba00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Train and evaluate a logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f4ea79ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8260\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with cross-validation\n",
    "scores = cross_val_score(log_reg, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Logistic Regression Accuracy: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0afaae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved as logistic_regression_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Predict and Export CSV\n",
    "# Predict on the test dataset and save submission file\n",
    "y_pred = log_reg.predict(X_test)\n",
    "output = pd.DataFrame({\"PassengerId\": test_data.index, \"Survived\": y_pred})\n",
    "output.to_csv(\"logistic_regression_submission.csv\", index=False)\n",
    "print(\"Submission saved as logistic_regression_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5016249a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "# Train Gradient Boosting Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "gb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "87c01b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.8272\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with cross-validation\n",
    "scores = cross_val_score(gb_clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Gradient Boosting Accuracy: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a81faf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved as gradient_boosting_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Predict and Export CSV\n",
    "y_pred = gb_clf.predict(X_test)\n",
    "output = pd.DataFrame({\"PassengerId\": test_data.index, \"Survived\": y_pred})\n",
    "output.to_csv(\"gradient_boosting_submission.csv\", index=False)\n",
    "print(\"Submission saved as gradient_boosting_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc03019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking Classifier\n",
    "# Feature Engineering\n",
    "def age_group(age):\n",
    "    if pd.isnull(age):\n",
    "        return \"Unknown\"\n",
    "    elif age < 13:\n",
    "        return \"Child\"\n",
    "    elif age < 18:\n",
    "        return \"Teen\"\n",
    "    elif age < 35:\n",
    "        return \"YoungAdult\"\n",
    "    elif age < 60:\n",
    "        return \"Adult\"\n",
    "    else:\n",
    "        return \"Senior\"\n",
    "\n",
    "for data in (train_data, test_data):\n",
    "    data[\"RelativesOnboard\"] = data[\"SibSp\"] + data[\"Parch\"]\n",
    "    data[\"IsAlone\"] = (data[\"RelativesOnboard\"] == 0).astype(int)\n",
    "    data[\"Title\"] = data[\"Name\"].str.extract(r',\\s*([^\\.]+)\\.')\n",
    "    data[\"Deck\"] = data[\"Cabin\"].str[0].fillna(\"U\")\n",
    "    data[\"AgeGroup\"] = data[\"Age\"].apply(age_group)\n",
    "    data[\"IsMarried\"] = (data[\"Title\"] == \"Mrs\").astype(int)\n",
    "    data[\"GroupSize\"] = data.groupby(\"Ticket\")[\"Name\"].transform(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28d3a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Pipelines\n",
    "num_attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"RelativesOnboard\", \"GroupSize\"]\n",
    "cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\", \"Title\", \"Deck\", \"IsAlone\", \"AgeGroup\", \"IsMarried\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "])\n",
    "\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs)\n",
    "])\n",
    "\n",
    "X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "y_train = train_data[\"Survived\"]\n",
    "X_test = preprocess_pipeline.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50700eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf', RandomForestClassifier(random_state=42)),\n",
       "                               ('svc', SVC(probability=True, random_state=42)),\n",
       "                               ('gb',\n",
       "                                GradientBoostingClassifier(random_state=42))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacking Classifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "        ('svc', SVC(probability=True, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(random_state=42))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "stack_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e3a3e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Accuracy: 0.8305\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation Evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(stack_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Stacked Model Accuracy: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc35c926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved as stacking_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Predict and Export CSV\n",
    "y_pred = stack_model.predict(X_test)\n",
    "output = pd.DataFrame({\"PassengerId\": test_data.index, \"Survived\": y_pred})\n",
    "output.to_csv(\"stacking_submission.csv\", index=False)\n",
    "print(\"Submission saved as stacking_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6da72dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC (Support Vector Classifier)\n",
    "# Feature Engineering\n",
    "train_data[\"RelativesOnboard\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\n",
    "train_data[\"IsAlone\"] = (train_data[\"RelativesOnboard\"] == 0).astype(int)\n",
    "train_data[\"Title\"] = train_data[\"Name\"].str.extract(r',\\s*([^\\.]+)\\.')\n",
    "train_data[\"AgeBucket\"] = train_data[\"Age\"] // 15 * 15\n",
    "train_data[\"Deck\"] = train_data[\"Cabin\"].str[0].fillna(\"U\")\n",
    "\n",
    "test_data[\"RelativesOnboard\"] = test_data[\"SibSp\"] + test_data[\"Parch\"]\n",
    "test_data[\"IsAlone\"] = (test_data[\"RelativesOnboard\"] == 0).astype(int)\n",
    "test_data[\"Title\"] = test_data[\"Name\"].str.extract(r',\\s*([^\\.]+)\\.')\n",
    "test_data[\"AgeBucket\"] = test_data[\"Age\"] // 15 * 15\n",
    "test_data[\"Deck\"] = test_data[\"Cabin\"].str[0].fillna(\"U\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "464464a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Pipelines\n",
    "\n",
    "num_attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"RelativesOnboard\"]\n",
    "cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\", \"Title\", \"Deck\", \"IsAlone\", \"AgeBucket\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "])\n",
    "\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs)\n",
    "])\n",
    "\n",
    "X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "y_train = train_data[\"Survived\"]\n",
    "X_test = preprocess_pipeline.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f5cea4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=42)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Support Vector Classifier Model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svc_clf = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svc_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "52a3f624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Accuracy: 0.8339\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with cross-validation\n",
    "scores = cross_val_score(svc_clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Support Vector Classifier Accuracy: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "030c771f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved as svc_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Predict and Export CSV\n",
    "y_pred = svc_clf.predict(X_test)\n",
    "output = pd.DataFrame({\"PassengerId\": test_data.index, \"Survived\": y_pred})\n",
    "output.to_csv(\"svc_submission.csv\", index=False)\n",
    "print(\"Submission saved as svc_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
